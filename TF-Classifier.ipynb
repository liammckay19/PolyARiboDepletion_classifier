{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "clinical = pd.read_csv('/data/archive/compendium/v5/clinical.tsv',\n",
    "                       sep='\\t').rename(columns={'th_sampleid': 'THid'}).set_index('THid')\n",
    "\n",
    "ribodDiagnosis = pd.read_csv('data/riboDepleted_samples_that_passedQC_and_have_known_diagnosis.tsv',\n",
    "                             sep='\\t').rename(columns={'Treehouse SAMPLE identifier': 'THid',\n",
    "                                                       'Diagnosis/Disease': 'disease'}).set_index('THid')\n",
    "ribodDiagnosis['TR_method'] = 'RiboMinus'\n",
    "\n",
    "methods = pd.read_csv('data/TranscriptMethod_THPEDv1.csv'\n",
    "                      ).rename(columns={'Treehouse SAMPLE identifier': 'THid'}).set_index('THid')\n",
    "\n",
    "clinicalIdTissue = clinical[['anat_sample', 'disease']] \n",
    "label_df = pd.merge(clinicalIdTissue, ribodDiagnosis, how='outer', left_index=True, right_index=True)\n",
    "label_df = pd.merge(label_df, methods, how='left', left_index=True, right_index=True)\n",
    "\n",
    "label_df['disease_y'].fillna(label_df['disease_x'], inplace=True)\n",
    "label_df['TR_method_y'].fillna(label_df['TR_method_x'], inplace=True)\n",
    "label_df = label_df.rename(columns={'TR_method_y': 'TR_method', 'disease_y': 'disease',\n",
    "                                    'anat_sample': 'tissue'})\n",
    "del label_df['disease_x'], label_df['TR_method_x']\n",
    "# here I do not use the tissue label, so I reduce label_df to only the prep type\n",
    "label_df = label_df['TR_method'].dropna()\n",
    "\n",
    "label_df = (label_df == 'PolyA').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "gene_df = pd.read_hdf('/data/archive/compendium/v5/v5_hugo_log2tpm.11340x58581.2018-02-03.hd5')\n",
    "gene_df = gene_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gene_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, select some data to put in the variables train_data, train_labels, test_data, test_labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, train_labels = None, None\n",
    "test_data, test_labels = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Then the following cells with produce the optimal weight vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# dont worry about this\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_batches = n_train // batch_size\n",
    "n_epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "train_batches = train_dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "train_next_batch = train_batches.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
    "test_batches = test_dataset.shuffle(1000).repeat().batch(n_test)\n",
    "test_next_batch = test_batches.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "N_GENES = 58581"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, N_GENES), name='gene_set')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name='prep_type')\n",
    "\n",
    "w = tf.Variable(tf.random_normal(shape=(N_GENES, 1), stddev=1/np.sqrt(N_GENES)), name='weight')\n",
    "h = tf.matmul(x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "per_sample_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=h)\n",
    "loss = tf.reduce_mean(per_sample_loss)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "update_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "losses = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op.run()\n",
    "    \n",
    "    for _ in range(n_epochs * n_batches):\n",
    "\n",
    "        trn_x, trn_y = sess.run(train_next_batch)\n",
    "        sess.run(update_step, feed_dict={x: trn_x, y: trn_y[:, None]})\n",
    "    \n",
    "    print('Final learned weight vector')\n",
    "    w_vec = w.eval()\n",
    "    print(w_vec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
